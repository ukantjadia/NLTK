# -*- coding: utf-8 -*-
"""cleaning_data

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MmQBgZbh8b1WlaIvAUcTWkoJN6O6rLNz
"""

import nltk 
nltk.download('words')
nltk.download('all')

import pandas as pd
import numpy as np
import re
!pip install emoji
import emoji

from google.colab import drive
drive.mount('/content/drive')

url = 'https://raw.githubusercontent.com/ukantjadia/NLTK/Main/tweets_data.csv'
df = pd.read_csv(url)
df.head(20)

words = set(nltk.corpus.words.words())
def cleaner(tweet):
    tweet = re.sub("@[A-Za-z0-9]+","",tweet) #Remove @ sign
    tweet = re.sub(r"(?:\@|http?\://|https?\://|www)\S+", "", tweet) #Remove http links
    tweet = " ".join(tweet.split())
    tweet = tweet.replace("#", "").replace("_", " ") #Remove hashtag sign but keep the text
    tweet = " ".join(w for w in nltk.wordpunct_tokenize(tweet) \
         if w.lower() in words or not w.isalpha())
    return tweet

def remove_emoji(data):
    emoj = re.compile("["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
        u"\U00002500-\U00002BEF"  # chinese char
        u"\U00002702-\U000027B0"
        u"\U00002702-\U000027B0"
        u"\U000024C2-\U0001F251"
        u"\U0001f926-\U0001f937"
        u"\U00010000-\U0010ffff"
        u"\u2640-\u2642" 
        u"\u2600-\u2B55"
        u"\u200d"
        u"\u23cf"
        u"\u23e9"
        u"\u231a"
        u"\ufe0f"  
        u"\u3030"
                      "]+", re.UNICODE)
    return re.sub(emoj, '', data)

df['content'] = df['content'].map(lambda x: cleaner(x))
df['content'] = df['content'].apply(remove_emoji)
pattern = r'[^\w\s]|_'
df['content'] = df['content'].replace(pattern,"",regex=True) # removing special character like %!$,:;+=()`&@
df['content'] = df['content'].str.strip()

df = df[df['content'].str.len() >= 10] # removing entry less than length 10 


df.to_csv('/content/drive/My Drive/edited_tweets.csv') #specify location

df_edited = pd.read_csv('/content/drive/My Drive/edited_tweets.csv')
df_edited.head(20)